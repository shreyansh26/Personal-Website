---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Academic Log | June/July 2022"
subtitle: ""
summary: ""
authors: ["Shreyansh Singh"]
tags: [reading-list, nlp, annotated paper, gpu, deep learning]
categories: [Machine Learning, Computer Science]
date: 2022-08-04T00:27:33+05:30
lastmod: 2022-08-04T00:27:33+05:30
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

A collection of academic papers/blogs/talks/projects that I read/watched/explored during the month. I also include any small (or large) personal projects that I did and any such related ML/non-ML work.

## Personal Projects

- **Paper re-implementation** - "Extracting Training Data from Large Language Models" by Carlini et al., 2021. - [[Github]](https://github.com/shreyansh26/Extracting-Training-Data-from-Large-Langauge-Models)

## Annotated Papers

- [Learning Backward Compatible Embeddings](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/General-DL/Learning%20Backward%20Compatible%20Embeddings.pdf)
- [Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/LLMs/Memorization%20Without%20Overfitting%20-%20Analyzing%20the%20Training%20Dynamics%20of%20Large%20Language%20Models.pdf)
- [Tracing Knowledge in Language Models Back to the Training Data](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/LLMs/Tracing%20Knowledge%20in%20Language%20Models%20Back%20to%20the%20Training%20Data.pdf)

## Papers I read

- [On the Unreasonable Effectiveness of Feature propagation in Learning on Graphs with Missing Node Features](https://arxiv.org/abs/2111.12128)
- [PaLM: Scaling Language Modeling with Pathways](https://arxiv.org/abs/2204.02311)
- [Hierarchical Text-Conditional Image Generation with CLIP Latents](https://cdn.openai.com/papers/dall-e-2.pdf)
- [Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language](https://arxiv.org/abs/2204.00598)
- [Unified Contrastive Learning in Image-Text-Label Space](https://arxiv.org/abs/2204.03610v1)
- [Improving Passage Retrieval with Zero-Shot Question Generation](https://arxiv.org/abs/2204.07496)
- [Exploring Dual Encoder Architectures for Question Answering](https://arxiv.org/abs/2204.07120)
- [Efficient Fine-Tuning of BERT Models on the Edge](https://arxiv.org/abs/2205.01541)
- [Fine-Tuning Transformers: Vocabulary Transfer](https://arxiv.org/abs/2112.14569)
- [Manipulating SGD with Data Ordering Attacks](https://arxiv.org/abs/2104.09667)
- [Differentially Private Fine-tuning of Language Models](https://openreview.net/forum?id=Q42f0dfjECO)
- [Extracting Training Data from Large Language Models](https://arxiv.org/abs/2012.07805)
- [Learning Backward Compatible Embeddings](https://arxiv.org/abs/2206.03040)
- [Compacter: Efficient Low-Rank Hypercomplex Adapter Layers](https://arxiv.org/abs/2106.04647)
- [Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift](https://arxiv.org/abs/2206.13089)
- [Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models](https://arxiv.org/abs/2205.10770)
- [Tracing Knowledge in Language Models Back to the Training Data](https://arxiv.org/abs/2205.11482)

## Blogs I read

- [Domain Adaptation with Generative Pseudo-Labeling (GPL)](https://www.pinecone.io/learn/gpl/)
- [Making Deep Learning Go Brrrr From First Principles](https://horace.io/brrr_intro.html)
- [Introduction to TorchScript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)
- [Nonlinear Computation in Deep Linear Networks](https://openai.com/blog/nonlinear-computation-in-linear-networks/)

## Talks I watched

- [How GPU Computing Works](https://www.nvidia.com/en-us/on-demand/session/gtcspring21-s31151/)

------

&nbsp;

<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script>

<!-- <button style="background-color: #70ab17; color: #1770AB" id="openpopup">Subscribe to my posts!</button> -->
<div class="button_cont" align="center"><button id="openpopup" class="example_a">Subscribe to my posts!</button></div>

<style>
    .example_a {
        color: #fff !important;
        text-transform: uppercase;
        text-decoration: none;
        background: #3f51b5;
        padding: 20px;
        border-radius: 5px;
        cursor: pointer;
        display: inline-block;
        border: none;
        transition: all 0.4s ease 0s;
    }

    .example_a:hover {
        background: #434343;
        letter-spacing: 1px;
        -webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        -moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        box-shadow: 5px 40px -10px rgba(0,0,0,0.57);
        transition: all 0.4s ease 0s;
    }
</style>


<script type="text/javascript">

function showMailingPopUp() {
    window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us4.list-manage.com","uuid":"0b10ac14f50d7f4e7d11cf26a","lid":"667a1bb3da","uniqueMethods":true}) })

    document.cookie = "MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC";
}

document.getElementById("openpopup").onclick = function() {showMailingPopUp()};

</script>

&nbsp;  

<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js" data-id="shreyanshsingh" data-description="Support me on Buy me a coffee!" data-message="" data-color="#FF5F5F" data-position="Right" data-x_margin="18" data-y_margin="18"></script>

Follow me on [Twitter](https://twitter.com/shreyansh_26), [Github](https://github.com/shreyansh26) or connect on [LinkedIn](https://www.linkedin.com/in/shreyansh26/).