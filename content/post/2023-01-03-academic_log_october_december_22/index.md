---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Academic Log | October-December 2022"
subtitle: ""
summary: ""
authors: ["Shreyansh Singh"]
tags: [reading-list, nlp, annotated paper, deep learning]
categories: [Machine Learning, Computer Science]
date: 2023-01-03T22:16:12+05:30
lastmod: 2023-01-03T22:16:12+05:30
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

A collection of academic papers/blogs/talks/projects that I read/watched/explored during the month. I also include any small (or large) personal projects that I did and any such related ML/non-ML work.

## Personal Projects
- **Paper re-implementation** - Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability by Cohen et al., 2021 - [[Github]](https://github.com/shreyansh26/Gradient-Descent-on-Neural-Networks-Typically-Occurs-at-the-Edge-of-Stability)
- **Paper re-implementation** - The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks by Frankle et al., 2018 - [[Github]](https://github.com/shreyansh26/Lottery-Ticket-Hypothesis)
- **Paper re-implementation** -An Empirical Model of Large-Batch Training by OpenAI, 2018 - [[Github]](https://github.com/shreyansh26/An-Empirical-Model-of-Large-Batch-Training)


## Annotated Papers
- [The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/The%20Lottery%20Ticket%20Hypothesis%20-%20Finding%20Sparse%2C%20Trainable%20Neural%20Networks%20.pdf)
- [Gradient Descent on Neural Networks Typically Occurs at the Edge of Stability](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Gradient%20Descent%20on%20Neural%20Networks%20Typically%20Occurs%20at%20the%20Edge%20of%20Stability.pdf)
- [Modeling Language Usage and Listener Engagement in Podcasts](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/General-DL/Modeling%20Language%20Usage%20and%20Listener%20Engagement%20in%20Podcasts.pdf)
- [Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a Noisy Quadratic Model](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Which%20Algorithmic%20Choices%20Matter%20at%20Which%20Batch%20Sizes_%20Insights%20From%20a%20Noisy%20Quadratic%20Model.pdf)
- [An Empirical Model of Large-Batch Training](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/An%20Empirical%20Model%20of%20Large-Batch%20Training.pdf)
- [Fine-Tuning Language Models from Human Preferences](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/An%20Empirical%20Model%20of%20Large-Batch%20Training.pdf)
- [Training language models to follow instructions with human feedback](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/LLMs/RLHF/Training%20language%20models%20to%20follow%20instructions%20with%20human%20feedback.pdf)
- [Adam: A Method for Stochastic Optimization](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Adam%20-%20A%20Method%20for%20Stochastic%20Optimization.pdf)
- [Monolith: Real Time Recommendation System With Collisionless Embedding Table](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/RecSys/Monolith%20-%20Real%20Time%20Recommendation%20System%20With%20Collisionless%20Embedding%20Table.pdf)
- [Limitations of the NTK for Understanding Generalization in Deep Learning](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/Limitations%20of%20the%20NTK%20for%20Understanding%20Generalization%20in%20Deep%20Learning.pdf)
- [What can linearized neural networks actually say about generalization?](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/ML%20Theory/What%20can%20linearized%20neural%20networks%20actually%20say%20about%20generalization.pdf)
- [GLM-130B: An Open Bilingual Pre-trained Model](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/LLMs/GLM-130B%20-%20An%20Open%20Bilingual%20Pre-trained%20Model.pdf)
- [Augmenting Netflix Search with In-Session Adapted Recommendations](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/RecSys/Augmenting%20Netflix%20Search%20with%20In-Session%20Adapted%20Recommendations.pdf)
- [Adversary or Friend? An adversarial Approach to Improving Recommender Systems](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/RecSys/Adversary%20or%20Friend%20-%20An%20adversarial%20Approach%20to%20Improving%20Recommender%20Systems.pdf)

## Papers I read (in addition to above)
- [How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources](https://www.notion.so/How-does-GPT-Obtain-its-Ability-Tracing-Emergent-Abilities-of-Language-Models-to-their-Sources-b9a57ac0fcf74f30a1ab9e3e36fa1dc1)
- [Artificial Interrogation for Attributing Language Models](https://arxiv.org/abs/2211.10877)
- [Deep Learning on a Data Diet: Finding Important Examples Early in Training](https://arxiv.org/abs/2107.07075)
- [BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning](https://arxiv.org/abs/2211.05610)
- [Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data](https://arxiv.org/abs/2110.13048)
- [Confidence-Ranked Reconstruction of Census Microdata from Published Statistics](https://arxiv.org/abs/2211.03128)
- [How Optimal is Greedy Decoding for Extractive Question Answering?](https://arxiv.org/abs/2108.05857)
- [The Curious Case of Absolute Position Embeddings](https://arxiv.org/abs/2210.12574)
- [Finding the smallest or largest element of a tensor from its low-rank factors](https://arxiv.org/abs/2210.11413v1)
- [GreaseLM: Graph REASoning Enhanced Language Models for Question Answering](https://arxiv.org/abs/2201.08860)
- [QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering](https://arxiv.org/abs/2104.06378)
- [Red-Teaming the Stable Diffusion Safety Filter](https://arxiv.org/abs/2210.04610)
- [Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale](https://arxiv.org/abs/1812.00417)

## Blogs I read

- [Notifications: why less is more — how Facebook has been increasing both user satisfaction and app usage by sending only a few notifications | by Analytics at Meta | Dec, 2022 | Medium](https://medium.com/@AnalyticsAtMeta/notifications-why-less-is-more-how-facebook-has-been-increasing-both-user-satisfaction-and-app-9463f7325e7d)
- [Feature Engineering for Personalized Search (fennel.ai)](https://fennel.ai/blog/feature-engineering-for-personalized-search/)
- [Are brain implants the future of computing? - YouTube](https://www.youtube.com/watch?v=BYxzrFyES6I&ab_channel=TheEconomist)
- [A New Way to Achieve Nuclear Fusion: Helion](https://www.youtube.com/watch?v=_bDXXWQxK38)
- [The secret lives of MI6’s top female spies](https://www.ft.com/content/741772c0-ee76-4d3d-bfcd-4fabc1fb405d)
- [Re-examining LayerNorm](https://www.lesswrong.com/posts/jfG6vdJZCwTQmG7kb/re-examining-layernorm) + [Code](https://colab.research.google.com/drive/1S39-w4vzX3VzZx_27X_BtrLs442pOJnJ?usp=sharing)
- [Mysteries of Mode Collapse due to RLHF](https://www.lesswrong.com/posts/t9svvNPNmFf5Qa3TA/mysteries-of-mode-collapse-due-to-rlhf)
- [Will we run out of ML data evidence from projecting dataset](https://www.lesswrong.com/posts/Couhhp4pPHbbhJ2Mg/will-we-run-out-of-ml-data-evidence-from-projecting-dataset)
- [Generating Human-level Text with Contrastive Search in Transformers](https://huggingface.co/blog/introducing-csearch)
- [How I learn machine learning | ★❤✰ Vicki Boykis ★❤✰](https://vickiboykis.com/2022/11/10/how-i-learn-machine-learning/)
- [Emerging Research & Applications of Large Language Models (w/ Google Brain, Replit, & HuggingFace) - YouTube](https://www.youtube.com/watch?v=r7UfYlFj2xw&ab_channel=InnovationEndeavors)
- https://github.com/srush/GPU-Puzzles
- [How Pinterest Leverages Realtime User Actions in Recommendation to Boost Homefeed Engagement Volume | by Pinterest Engineering | Pinterest Engineering Blog | Nov, 2022 | Medium](https://medium.com/pinterest-engineering/how-pinterest-leverages-realtime-user-actions-in-recommendation-to-boost-homefeed-engagement-volume-165ae2e8cde8)
- [(1) Real-Time Research Recording: Can a Transformer Re-Derive Positional Info? - YouTube](https://www.youtube.com/watch?v=yo4QvDn-vsU&ab_channel=NeelNanda)
- [Neural Tangent Kernel Distillation - LessWrong](https://www.lesswrong.com/posts/QzpKq92nXqp8NHM34/neural-tangent-kernel-distillation)
- [Generating Human-level Text with Contrastive Search in Transformers](https://twitter.com/__nmca__/status/1588575691284807682?s=20&t=Yea0IQkI3v8VjiEAx1l8ow)
- [Ethan Caballero–Broken Neural Scaling Laws - YouTube](https://www.youtube.com/watch?v=SV87S38M1J4&ab_channel=TheInsideView)
- [Reducing Instagram’s basic video compute time by 94 percent (fb.com)](https://engineering.fb.com/2022/11/04/video-engineering/instagram-video-processing-encoding-reduction/)
- [Real-Time Research Recording: Can a Transformer Re-Derive Positional Info? - YouTube](https://www.youtube.com/watch?v=yo4QvDn-vsU&feature=youtu.be&ab_channel=NeelNanda)
- NTK
  - [Some Math behind Neural Tangent Kernel | Lil'Log (lilianweng.github.io)](https://lilianweng.github.io/posts/2022-09-08-ntk/)
  - [Understanding the Neural Tangent Kernel – Rajat's Blog – A blog about machine learning and math. (rajatvd.github.io)](https://rajatvd.github.io/NTK/)
- Gaussian Processes
  - [A Visual Exploration of Gaussian Processes](https://distill.pub/2019/visual-exploration-gaussian-processes/)
  - [Fitting Gaussian Process Models in Python](https://www.dominodatalab.com/blog/fitting-gaussian-process-models-python)

## Courses

- Revisited some of the [lectures of Advanced NLP (Fall'22)](https://youtube.com/playlist?list=PL8PYTP1V4I8D0UkqW2fEhgLrnlDW9QK7z) having completed the Fall'21 set of lectures in early 2022.

------

&nbsp;

<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script>

<!-- <button style="background-color: #70ab17; color: #1770AB" id="openpopup">Subscribe to my posts!</button> -->
<div class="button_cont" align="center"><button id="openpopup" class="example_a">Subscribe to my posts!</button></div>

<style>
    .example_a {
        color: #fff !important;
        text-transform: uppercase;
        text-decoration: none;
        background: #3f51b5;
        padding: 20px;
        border-radius: 5px;
        cursor: pointer;
        display: inline-block;
        border: none;
        transition: all 0.4s ease 0s;
    }

    .example_a:hover {
        background: #434343;
        letter-spacing: 1px;
        -webkit-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        -moz-box-shadow: 0px 5px 40px -10px rgba(0,0,0,0.57);
        box-shadow: 5px 40px -10px rgba(0,0,0,0.57);
        transition: all 0.4s ease 0s;
    }
</style>


<script type="text/javascript">

function showMailingPopUp() {
    window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us4.list-manage.com","uuid":"0b10ac14f50d7f4e7d11cf26a","lid":"667a1bb3da","uniqueMethods":true}) })

    document.cookie = "MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC";
}

document.getElementById("openpopup").onclick = function() {showMailingPopUp()};

</script>

&nbsp;  
